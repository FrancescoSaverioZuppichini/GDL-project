{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxUUcdYRfR2r"
   },
   "source": [
    "# Dynamic Graph CNN\n",
    "Francesco Saverio Zuppichini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829) for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoxKRIT-PJlX"
   },
   "source": [
    "## Data loading\n",
    "Let's get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import ModelNet\n",
    "import torch_geometric.transforms as T\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBU66FN-PNnU"
   },
   "outputs": [],
   "source": [
    "pre_transform = T.NormalizeScale()\n",
    "transform = T.Compose([T.SamplePoints(1024),\n",
    "                       T.RandomRotate(30), \n",
    "                       T.RandomScale((0.5,2)), \n",
    "                       ])\n",
    "name = '40'\n",
    "\n",
    "train_ds = ModelNet(root='./',\n",
    "             train=True,\n",
    "             name=name,\n",
    "             pre_transform=pre_transform,\n",
    "             transform=transform)\n",
    "\n",
    "test_ds = ModelNet(root='./',\n",
    "             train=True,\n",
    "             name=name,\n",
    "             pre_transform=pre_transform,\n",
    "             transform = T.SamplePoints(1024 * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TwdXt99tQUh"
   },
   "source": [
    "Now we have to define our dataloader, these guys will handle the thread queue to feed the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzDpHGpfQGGs"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dl = DataLoader(test_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSAivhUEWEaS"
   },
   "source": [
    "## Model\n",
    "\n",
    "Define our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hxkdZfgWaoP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "from torch.nn import Sequential, Linear, ReLU, BatchNorm2d\n",
    "from torch_geometric.nn import EdgeConv, knn_graph, global_max_pool\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, BatchNorm1d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# BatchNorm1d does not work well with our images dataset, uncomment it to load the pretrain weights\n",
    "# for the ModelNet40\n",
    "class DynamicEdgeConv(gnn.EdgeConv):\n",
    "    def __init__(self, k = 6, * args, ** kwargs):\n",
    "        super().__init__( * args, ** kwargs)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, pos, batch):\n",
    "        edge_index = knn_graph(pos, self.k, batch, loop = False)\n",
    "        return super().forward(pos, edge_index)\n",
    "\n",
    "def fc_block(in_features, out_features):\n",
    "    return Seq(\n",
    "        Linear(in_features, out_features),\n",
    "        BatchNorm1d(out_features),\n",
    "        ReLU(inplace=True))\n",
    "\n",
    "class DGCNNClassification(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, k = 20):\n",
    "        super(DGCNNClassification, self).__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            DynamicEdgeConv(\n",
    "                k = k,\n",
    "                nn = Sequential(\n",
    "                    fc_block(in_channels * 2, 64),\n",
    "                    fc_block(64, 64),\n",
    "                    fc_block(64, 64),\n",
    "                ),\n",
    "                aggr = 'max'),\n",
    "            DynamicEdgeConv(\n",
    "                k = k,\n",
    "                nn = fc_block(64 * 2, 128),          \n",
    "                aggr = 'max')\n",
    "        ])\n",
    "\n",
    "#         self.point_wise_features2higher_dim = fc_block(128, 512) # uncomment to try to bottleneck DGCNN \n",
    "        self.point_wise_features2higher_dim = fc_block(128, 1024)           \n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            fc_block(1024, 512), # commet it to try to bottleneck DGCNN  \n",
    "            fc_block(512, 256), \n",
    "            fc_block(256, n_classes)      \n",
    "        )\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.BatchNorm1d): # very similar to resnet\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x, batch):\n",
    "        out = x \n",
    "        for conv in self.convs:\n",
    "            out = conv(out, batch)# it can be updated to use skipped connection \n",
    "        out = self.point_wise_features2higher_dim(out)\n",
    "        out = global_max_pool(out, batch)\n",
    "        out = self.tail(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9QVyWjxtZZb"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_dir(name):\n",
    "    now = time.time()\n",
    "    save_dir = './model-{}-{}.pt'.format(name, str(now).replace('.', '-'))\n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = DGCNNClassification(3,40).to(device)\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(epochs, dl, save_dir, train=True):\n",
    "    bar = tqdm_notebook(range(epochs))\n",
    "    last_acc = 0\n",
    "    \n",
    "    for epoch in bar:\n",
    "        acc_tot = 0\n",
    "        if (epoch + 1) % 10 == 0: \n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr'] * 0.2\n",
    "        bbar = tqdm_notebook(dl, leave=False)\n",
    "        for i, data in enumerate(bbar):\n",
    "            start = time.time()\n",
    "            if train: optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            out = model(data.pos, data.batch)\n",
    "            preds = torch.argmax(out, dim=-1)\n",
    "            acc = (data.y == preds).float().sum() / preds.shape[0]\n",
    "            acc_v = acc.cpu().item()\n",
    "            acc_tot += acc_v\n",
    "            loss = criterion(out, data.y)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            bbar.set_description('[INFO] loss={:.2f} acc={:.2f}'.format(loss, acc_v))\n",
    "        mean_acc = acc_tot / i\n",
    "        if train:\n",
    "            if mean_acc > last_acc:\n",
    "                last_acc = mean_acc\n",
    "                torch.save(model.state_dict(), save_dir)\n",
    "\n",
    "        bar.set_description('[INFO] acc={:.3f} best={:.3f}'.format(mean_acc, last_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(50, train_dl, get_save_dir('40'), train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1758276,
     "status": "error",
     "timestamp": 1557931393583,
     "user": {
      "displayName": "Fra Zuppi",
      "photoUrl": "",
      "userId": "12410559444235213734"
     },
     "user_tz": -120
    },
    "id": "xqZ344YRqNlm",
    "outputId": "aadc6f23-0145-4ba4-e91c-ae7c768706a6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96726fe640db42ea8f936066b1717f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=616), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DGCNNClassification(3,40).to(device)\n",
    "model.load_state_dict(torch.load('./model-40-1559918906-8202357.pt'))\n",
    "model.eval()\n",
    "run(1, test_dl, 'tmp', train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversability Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "We have to convert each image to a graph, we can use `grid` to get the correct graph values and k-nn to reduce its dimensions. The following loads our custom dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import KNNGraph\n",
    "from torch_geometric.utils import grid\n",
    "\n",
    "class TraversabilityDataset(Dataset):\n",
    "    def __init__(self, df, hm,\n",
    "                 patches_dir,\n",
    "                 patch_size=None,\n",
    "                 tr=None,\n",
    "                 time_window=None,\n",
    "                 transform=None,\n",
    "                 more_than=None,\n",
    "                 less_than=None,\n",
    "                 down_sampling=None,\n",
    "                 transform_with_label=None,\n",
    "                 ):\n",
    "\n",
    "        self.df = df\n",
    "        self.hm = hm\n",
    "        self.patches_dir = patches_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.tr = tr\n",
    "        self.time_window = time_window\n",
    "\n",
    "        self.transform = transform\n",
    "        self.transform_with_label = transform_with_label\n",
    "        self.should_generate_paths = not 'images' in df\n",
    "\n",
    "        if 'advancement' not in self.df:\n",
    "            self.df = add_advancement(self.df, time_window)\n",
    "\n",
    "        if down_sampling is not None:\n",
    "            self.df = self.df[::down_sampling]\n",
    "\n",
    "        if more_than is not None: self.df = self.df[self.df['advancement'] >= more_than]\n",
    "        if less_than is not None: self.df = self.df[self.df['advancement'] <= less_than]\n",
    "        if tr is not None and len(self.df) > 0:\n",
    "            self.df[\"label\"] = self.df[\"advancement\"] > tr\n",
    "\n",
    "        if tr is None:\n",
    "            self.df[\"advancement\"][self.df[\"advancement\"] < 0] = 0\n",
    "\n",
    "\n",
    "    def read_patch(self, img_name):\n",
    "        patch = cv2.imread(self.patches_dir + '/' + img_name)\n",
    "        patch = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
    "        patch = cv2.resize(patch, (patch.shape[-2] // 2, patch.shape[-1] // 2)) \n",
    "        patch = patch.astype(np.float32)\n",
    "        patch /= 255\n",
    "        return patch\n",
    "\n",
    "    def generate_patch(self, row):\n",
    "        patch = hmpatch(self.hm, row[\"hm_x\"], row[\"hm_y\"], np.rad2deg(row['pose__pose_e_orientation_z']),\n",
    "                        self.patch_size,\n",
    "                        scale=1)[0]\n",
    "\n",
    "        return patch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[int(idx)]\n",
    "\n",
    "        if self.should_generate_paths:\n",
    "            patch = self.generate_patch(row)\n",
    "        else:\n",
    "            patch = self.read_patch(row['images'])\n",
    "\n",
    "        y = row['advancement']\n",
    "\n",
    "        if 'label' in self.df:\n",
    "            y = row['label'].astype(np.long)\n",
    "\n",
    "        if 'height' in row:\n",
    "            patch *= row['height']\n",
    "\n",
    "        y = torch.tensor(y)\n",
    "\n",
    "        if 'label' in self.df and self.transform_with_label is not None:\n",
    "            patch = self.transform_with_label(patch, row['label'])\n",
    "\n",
    "        return self.transform(patch), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    @classmethod\n",
    "    def from_meta(cls, meta, base_dir, hm_dir, n=None, *args, **kwargs):\n",
    "        datasets = []\n",
    "\n",
    "        for (idx, row) in meta.iterrows():\n",
    "            try:\n",
    "                df, hm = open_df_and_hm_from_meta_row(row, base_dir, hm_dir)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            if len(df) > 0: datasets.append(cls(df, hm, *args, **kwargs))\n",
    "        if n is not None: datasets = datasets[:n]\n",
    "        concat_ds = ConcatDataset(datasets)\n",
    "        concat_ds.c = 2\n",
    "        concat_ds.classes = 'False', 'True'\n",
    "\n",
    "        return concat_ds\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_dfs(concat_ds):\n",
    "        df = None\n",
    "        for ds in concat_ds.datasets:\n",
    "            if df is None:\n",
    "                df = ds.df\n",
    "            else:\n",
    "                df = pd.concat([df, ds.df], sort=True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        concat_ds.df = df\n",
    "        return concat_ds\n",
    "\n",
    "    @classmethod\n",
    "    def from_root(cls, root, n=None, *args, **kwargs):\n",
    "        dfs_paths = glob.glob(root + '/*.csv')\n",
    "        if len(dfs_paths) == 0: dfs_paths = glob.glob(root + '/**/*.csv')\n",
    "        datasets = []\n",
    "        for df_path in dfs_paths:\n",
    "            df = pd.read_csv(df_path)\n",
    "            if len(df) > 0:\n",
    "                datasets.append(cls(df, root, *args, **kwargs))\n",
    "        if n is not None: datasets = datasets[:n]\n",
    "\n",
    "        concat_ds = ConcatDataset(datasets)\n",
    "        concat_ds.c = 2\n",
    "        concat_ds.classes = 'False', 'True'\n",
    "\n",
    "        return concat_ds\n",
    "\n",
    "    @classmethod\n",
    "    def from_dfs(cls, dfs, root, *args, **kwargs):\n",
    "        datasets = []\n",
    "\n",
    "        for df in dfs:\n",
    "            if len(df) > 0:\n",
    "                datasets.append(cls(df, root, *args, **kwargs))\n",
    "\n",
    "        concat_ds = ConcatDataset(datasets)\n",
    "        concat_ds.c = 2\n",
    "        concat_ds.classes = 'False', 'True'\n",
    "        return concat_ds\n",
    "\n",
    "class CenterAndScalePatch():\n",
    "    \"\"\"\n",
    "    This class is used to center in the middle and rescale a given\n",
    "    patch. We need to center in the  middle in order to\n",
    "    decouple the root position from the classification task. Also,\n",
    "    depending on the map, we need to multiply the patch by a scaling factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale=1.0, debug=False, ):\n",
    "        self.scale = scale\n",
    "        self.debug = debug\n",
    "\n",
    "    def show_heatmap(self, x, title, ax):\n",
    "        ax.set_title(title)\n",
    "        img_n = x\n",
    "        sns.heatmap(img_n,\n",
    "                    ax=ax,\n",
    "                    fmt='0.2f')\n",
    "\n",
    "    def __call__(self, x, debug=False):\n",
    "        if self.debug: fig = plt.figure()\n",
    "\n",
    "        if self.debug:\n",
    "            ax = plt.subplot(2, 2, 1)\n",
    "            self.show_heatmap(x, 'original', ax)\n",
    "\n",
    "        x *= self.scale\n",
    "        if self.debug:\n",
    "            ax = plt.subplot(2, 2, 2)\n",
    "            self.show_heatmap(x, 'scale', ax)\n",
    "        center = x[x.shape[0] // 2, x.shape[1] // 2]\n",
    "        x -= center\n",
    "\n",
    "        if self.debug:\n",
    "            ax = plt.subplot(2, 2, 3)\n",
    "            self.show_heatmap(x, 'centered {}'.format(center), ax)\n",
    "\n",
    "        if self.debug:\n",
    "            ax = plt.subplot(2, 2, 4)\n",
    "            self.show_heatmap(x, 'final', ax)\n",
    "\n",
    "        if self.debug: plt.show()\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs from patches\n",
    "To create the graphs we can subclass TraversabilityDataset and on the fly use the `grid` function to make them graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraversabilityGraphDataset(TraversabilityDataset):\n",
    "    def __init__(self,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, y = super().__getitem__(idx)\n",
    "        img = img.squeeze()\n",
    "        edge_index, pos = grid(img.shape[-2], img.shape[-1])\n",
    "        pos = torch.cat([pos.float(), img.reshape(img.shape[-2] * img.shape[-1], 1)], dim=-1)\n",
    "        # we set it pos since in the .run function we where using the 3d point pos as feature\n",
    "        data = Data(pos=pos.float(), y=y.item())\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fzuppic/anaconda3/envs/gdl/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.nn import Dropout\n",
    "\n",
    "TRAIN_ROOT = '/home/fzuppic/data/test/'\n",
    "TEST_ROOT = '/home/fzuppic/data/test/100/'\n",
    "\n",
    "train_tr = Compose([CenterAndScalePatch(), ToTensor(), Dropout(0.1)])\n",
    "test_tr = Compose([CenterAndScalePatch(), ToTensor()])\n",
    "\n",
    "train_ds = TraversabilityGraphDataset.from_root(TRAIN_ROOT, \n",
    "                                                patches_dir=TRAIN_ROOT + '/patches/', \n",
    "                                                down_sampling=2,\n",
    "                                                transform=train_tr, \n",
    "                                                tr=0.2)\n",
    "\n",
    "test_ds = TraversabilityGraphDataset.from_root(TEST_ROOT, \n",
    "                                                patches_dir=TEST_ROOT + '/patches/', \n",
    "                                                down_sampling=2,\n",
    "                                                transform=train_tr, \n",
    "                                                tr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "model = DGCNNClassification(3,2, k=6).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), 0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 50\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(50, train_dl, get_save_dir('traversability'), train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea3bd1b8d1e46e09ca309f859e35dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DGCNNClassification(3,2).to(device)\n",
    "model.load_state_dict(torch.load('./model-traversability-1560089226-7143812.pt'))\n",
    "model.eval()\n",
    "run(1, test_dl, None, train=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DGCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
